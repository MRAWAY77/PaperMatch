{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "def merge_json_to_csv(metadata_folder='/home/lenovo3/Desktop/Alvin/NUS_ISS/PaperMatch/datasets/metadata/', output_csv='/home/lenovo3/Desktop/Alvin/NUS_ISS/PaperMatch/datasets/metadata/metadata.csv'):\n",
    "    all_data = []\n",
    "\n",
    "    # Get all JSON files in the metadata folder\n",
    "    json_files = glob(os.path.join(metadata_folder, '*.json'))\n",
    "\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                if isinstance(data, list):\n",
    "                    all_data.extend(data)\n",
    "                elif isinstance(data, dict):\n",
    "                    all_data.append(data)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error reading {json_file}: {e}\")\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"No valid data found in the JSON files.\")\n",
    "        return\n",
    "\n",
    "    # Convert to DataFrame and save as CSV\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Metadata saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "merge_json_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def generate_cluster_csvs(metadata_csv='/home/lenovo3/Desktop/Alvin/NUS_ISS/PaperMatch/datasets/academic_metadata.csv', parent_folder='/home/lenovo3/Desktop/Alvin/NUS_ISS/PaperMatch/datasets/Academic_Clusters/Organised_Crime_and_Drug_Trafficking/'):\n",
    "    # Load the metadata CSV\n",
    "    metadata_df = pd.read_csv(metadata_csv)\n",
    "\n",
    "    # Ensure filename column exists\n",
    "    if 'filename' not in metadata_df.columns:\n",
    "        raise ValueError(\"'filename' column not found in the metadata CSV.\")\n",
    "\n",
    "    # Go through each subfolder (cluster) in parent folder\n",
    "    for subdir in os.listdir(parent_folder):\n",
    "        subdir_path = os.path.join(parent_folder, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            # Get all filenames in the subfolder\n",
    "            subfolder_filenames = set(os.listdir(subdir_path))\n",
    "\n",
    "            # Filter metadata by filenames in the subfolder\n",
    "            matched_df = metadata_df[metadata_df['filename'].isin(subfolder_filenames)]\n",
    "\n",
    "            # Save filtered CSV in the same subfolder\n",
    "            output_path = os.path.join(subdir_path, 'cluster_metadata.csv')\n",
    "            matched_df.to_csv(output_path, index=False)\n",
    "            print(f\"Saved {len(matched_df)} records to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "generate_cluster_csvs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_similarity_dict_from_file(filepath):\n",
    "    topic_dict = {}\n",
    "    current_topic = None\n",
    "    inside_block = False\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # Detect topic title\n",
    "            if not inside_block and not line.startswith('{'):\n",
    "                current_topic = line\n",
    "                topic_dict[current_topic] = {}\n",
    "                continue\n",
    "\n",
    "            # Start of similarity dictionary block\n",
    "            if line.startswith('{'):\n",
    "                inside_block = True\n",
    "                continue\n",
    "\n",
    "            # End of similarity dictionary block\n",
    "            if line.startswith('}'):\n",
    "                inside_block = False\n",
    "                current_topic = None\n",
    "                continue\n",
    "\n",
    "            # Key-value pairs\n",
    "            if inside_block and ':' in line:\n",
    "                try:\n",
    "                    key, value = line.split(':', 1)\n",
    "                    key = key.strip().strip(\"'\\\"\")  # remove quotes\n",
    "                    value = float(value.strip().rstrip(','))\n",
    "                    topic_dict[current_topic][key] = value\n",
    "                except ValueError:\n",
    "                    print(f\"Skipping invalid line: {line}\")\n",
    "\n",
    "    return topic_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import math\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def plot_similarity_graphs_from_dict(topic_dict, output_dir='output_graphs'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for topic, sim_dict in topic_dict.items():\n",
    "        if not sim_dict:\n",
    "            continue\n",
    "\n",
    "        # Sort the items by similarity score in descending order\n",
    "        sorted_items = sorted(sim_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Select the top 20 pairs\n",
    "        top_pairs = sorted_items[:20]\n",
    "\n",
    "        # Create graph\n",
    "        G = nx.Graph()\n",
    "\n",
    "        for pair, similarity in top_pairs:\n",
    "            key1, key2 = pair.split(' -> ')\n",
    "            key1_renamed = key1.replace('cluster_', 'Acad_')\n",
    "            key2_renamed = f\"News_{key2}\"\n",
    "\n",
    "            G.add_node(key1_renamed, color='green')\n",
    "            G.add_node(key2_renamed, color='red')\n",
    "            G.add_edge(key1_renamed, key2_renamed, weight=similarity)\n",
    "\n",
    "        # Layout and drawing\n",
    "        pos = nx.spring_layout(G, seed=42)\n",
    "        node_colors = [G.nodes[node]['color'] for node in G.nodes]\n",
    "\n",
    "        plt.figure(figsize=(16, 12))\n",
    "        nx.draw(G, pos, with_labels=True, node_color=node_colors,\n",
    "                edge_color='gray', node_size=800, font_size=8)\n",
    "\n",
    "        # Draw edge labels with similarity scores\n",
    "        edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "        formatted_edge_labels = {k: f\"{v:.2f}\" for k, v in edge_labels.items()}\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels=formatted_edge_labels, font_size=6)\n",
    "\n",
    "        # Title for the graph\n",
    "        plt.title(f\"Semantic Similarity Graph: {topic}\", fontsize=14, fontweight='bold')\n",
    "\n",
    "        # Prepare the legend\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], marker='o', color='w', label='Academic Cluster (Acad_i)',\n",
    "                   markerfacecolor='green', markersize=10),\n",
    "            Line2D([0], [0], marker='o', color='w', label='News Segment (News_i)',\n",
    "                   markerfacecolor='red', markersize=10)\n",
    "        ]\n",
    "\n",
    "        # Add the top 20 pairs to the legend\n",
    "        for idx, (pair, similarity) in enumerate(top_pairs):\n",
    "            legend_elements.append(\n",
    "                Line2D([0], [0], color='gray', label=f\"{pair}: {similarity:.2f}\", linestyle='-', linewidth=1)\n",
    "            )\n",
    "\n",
    "        # Automatically adjust the legend position to avoid overlap with the graph\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Add the legend with dynamic positioning\n",
    "        legend = plt.legend(handles=legend_elements, fontsize=10, bbox_to_anchor=(1, 1), loc='upper left', frameon=True)\n",
    "        \n",
    "        # Save the figure to the specified path\n",
    "        filename = os.path.join(output_dir, f\"{topic.replace(' ', '_')}.png\")\n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25698/3418317108.py:63: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the file\n",
    "filepath = '/home/lenovo3/Desktop/Alvin/NUS_ISS/PaperMatch/Graph_Network/sim_score_graph_network.txt'\n",
    "topic_dict = load_similarity_dict_from_file(filepath)\n",
    "\n",
    "# Step 2: Generate graphs\n",
    "plot_similarity_graphs_from_dict(topic_dict, output_dir='/home/lenovo3/Desktop/Alvin/NUS_ISS/PaperMatch/Graph_Network/output_graphs')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "papermatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
