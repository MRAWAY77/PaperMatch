{
    "-1": {
        "Top_Words": [
            [
                "model",
                0.024218708611675046
            ],
            [
                "attack",
                0.023651663242946555
            ],
            [
                "fine",
                0.017256558074281544
            ],
            [
                "tuning",
                0.015300051723252822
            ],
            [
                "dataset",
                0.013052846782611018
            ],
            [
                "datum",
                0.013013471101097221
            ],
            [
                "backdoor",
                0.012680402370904604
            ],
            [
                "image",
                0.012557220085358346
            ],
            [
                "prompt",
                0.012406617173578858
            ],
            [
                "feature",
                0.012001327499435128
            ]
        ],
        "Papers": [
            "data-poisoning_74.pdf",
            "red-teaming_16.pdf",
            "backdoor-defense_53.pdf",
            "inference-attack_55.pdf",
            "data-poisoning_31.pdf",
            "red-teaming_42.pdf",
            "data-poisoning_6.pdf",
            "red-teaming_86.pdf",
            "red-teaming_22.pdf",
            "backdoor-attack_3.pdf",
            "backdoor-attack_12.pdf",
            "data-poisoning_3.pdf",
            "inference-attack_15.pdf",
            "red-teaming_71.pdf",
            "backdoor-attack_57.pdf",
            "red-teaming_17.pdf",
            "data-poisoning_20.pdf",
            "inference-attack_77.pdf",
            "time-series_98.pdf",
            "data-poisoning_70.pdf",
            "inference-attack_87.pdf",
            "backdoor-attack_33.pdf",
            "xai_87.pdf"
        ]
    },
    "0": {
        "Top_Words": [
            [
                "backdoor",
                0.027909881167021613
            ],
            [
                "acc",
                0.02640526465670205
            ],
            [
                "asr",
                0.023705588442459
            ],
            [
                "attack",
                0.021891221345478322
            ],
            [
                "trigger",
                0.021039787222815923
            ],
            [
                "clip",
                0.018221059201029545
            ],
            [
                "image",
                0.01793172660404057
            ],
            [
                "clean",
                0.016204720502925308
            ],
            [
                "model",
                0.015512117552994802
            ],
            [
                "poisoning",
                0.013046902432835154
            ]
        ],
        "Papers": [
            "data-poisoning_93.pdf",
            "data-poisoning_28.pdf",
            "backdoor-attack_37.pdf",
            "backdoor-attack_79.pdf",
            "backdoor-attack_23.pdf",
            "backdoor-attack_81.pdf",
            "real-world-adversarial-attack_3.pdf",
            "backdoor-attack_2.pdf",
            "backdoor-attack_100.pdf",
            "adversarial-attack_49.pdf",
            "backdoor-attack_40.pdf",
            "backdoor-attack_94.pdf",
            "data-poisoning_95.pdf",
            "data-poisoning_49.pdf",
            "backdoor-attack_82.pdf"
        ]
    },
    "1": {
        "Top_Words": [
            [
                "jailbreak",
                0.023985108140050226
            ],
            [
                "prompt",
                0.02233391296694505
            ],
            [
                "llm",
                0.01644410758835886
            ],
            [
                "strategy",
                0.014009270345988542
            ],
            [
                "response",
                0.013570290736132107
            ],
            [
                "wj",
                0.01286547066390806
            ],
            [
                "model",
                0.012786679308441157
            ],
            [
                "al",
                0.012717853063451606
            ],
            [
                "step",
                0.012326227567042769
            ],
            [
                "instruction",
                0.012288000181123368
            ]
        ],
        "Papers": [
            "data-poisoning_12.pdf",
            "red-teaming_32.pdf",
            "llm-jailbreak_2.pdf",
            "red-teaming_18.pdf",
            "red-teaming_78.pdf",
            "llm-jailbreak_6.pdf",
            "llm-jailbreak_8.pdf",
            "red-teaming_44.pdf",
            "red-teaming_81.pdf",
            "red-teaming_14.pdf",
            "red-teaming_38.pdf",
            "red-teaming_15.pdf",
            "red-teaming_33.pdf"
        ]
    },
    "2": {
        "Top_Words": [
            [
                "adversarial",
                0.026192582974609947
            ],
            [
                "image",
                0.01987711238482206
            ],
            [
                "method",
                0.019262160903617855
            ],
            [
                "suffix",
                0.01739999909336884
            ],
            [
                "advprompter",
                0.016158532413976086
            ],
            [
                "generate",
                0.015868275879476437
            ],
            [
                "adv",
                0.014375786779552646
            ],
            [
                "targetllm",
                0.014058874835381152
            ],
            [
                "prompt",
                0.013635628564828193
            ],
            [
                "model",
                0.013466818717471338
            ]
        ],
        "Papers": [
            "decoder_62.pdf",
            "adversarial-defense_95.pdf",
            "adversarial-attack_85.pdf",
            "adversarial-attack_5.pdf",
            "xai_34.pdf",
            "deepfake-detection_78.pdf",
            "inference-attack_91.pdf",
            "backdoor-attack_10.pdf",
            "adversarial-attack_32.pdf",
            "red-teaming_52.pdf",
            "adversarial-attack_95.pdf",
            "red-teaming_9.pdf"
        ]
    },
    "3": {
        "Top_Words": [
            [
                "graph",
                0.09240988157965385
            ],
            [
                "node",
                0.06590273120170503
            ],
            [
                "gnn",
                0.03618110759871271
            ],
            [
                "attack",
                0.03079756492591684
            ],
            [
                "model",
                0.026231267825894338
            ],
            [
                "label",
                0.02522933238495598
            ],
            [
                "condensation",
                0.02365772303232752
            ],
            [
                "classification",
                0.019951647245074748
            ],
            [
                "privacy",
                0.019617701771890813
            ],
            [
                "base",
                0.01913189275581058
            ]
        ],
        "Papers": [
            "node-classification_81.pdf",
            "inference-attack_84.pdf",
            "inference-attack_65.pdf",
            "adversarial-attack_66.pdf",
            "backdoor-attack_32.pdf",
            "adversarial-attack_28.pdf"
        ]
    },
    "4": {
        "Top_Words": [
            [
                "assessor",
                0.019506300350510576
            ],
            [
                "fine",
                0.016618834323545325
            ],
            [
                "tuning",
                0.015820409295247133
            ],
            [
                "apreprint",
                0.015268641995159019
            ],
            [
                "tuningalignedlanguagemodelscompromisessafety",
                0.014927982600559315
            ],
            [
                "etal",
                0.01471494970558604
            ],
            [
                "model",
                0.013834110300898709
            ],
            [
                "llm",
                0.013589821988351073
            ],
            [
                "chat",
                0.01282114222931201
            ],
            [
                "user",
                0.012773179312569662
            ]
        ],
        "Papers": [
            "benchmarking_93.pdf",
            "program-repair_5.pdf",
            "red-teaming_72.pdf",
            "inference-attack_2.pdf",
            "red-teaming_79.pdf",
            "red-teaming_49.pdf"
        ]
    },
    "5": {
        "Top_Words": [
            [
                "property",
                0.04774169299333401
            ],
            [
                "attack",
                0.039735345243213926
            ],
            [
                "poisoning",
                0.03874390037877772
            ],
            [
                "dataset",
                0.03315972591016959
            ],
            [
                "model",
                0.030765848861952938
            ],
            [
                "collision",
                0.02982849707416796
            ],
            [
                "target",
                0.022619160965549716
            ],
            [
                "poison",
                0.02257170609066642
            ],
            [
                "sample",
                0.01977784305882729
            ],
            [
                "rate",
                0.019542535787853237
            ]
        ],
        "Papers": [
            "data-poisoning_66.pdf",
            "data-poisoning_47.pdf",
            "neural-network-security_1.pdf",
            "inference-attack_45.pdf",
            "data-poisoning_69.pdf"
        ]
    },
    "6": {
        "Top_Words": [
            [
                "member",
                0.04945447213030539
            ],
            [
                "membership",
                0.04190088120292683
            ],
            [
                "attack",
                0.03980316550513033
            ],
            [
                "model",
                0.030221833061609776
            ],
            [
                "privacy",
                0.029487211109828614
            ],
            [
                "sample",
                0.02884032840114299
            ],
            [
                "inference",
                0.025999726141795867
            ],
            [
                "shadow",
                0.025565636621732862
            ],
            [
                "non",
                0.02364202019472745
            ],
            [
                "dataset",
                0.022073059604023986
            ]
        ],
        "Papers": [
            "inference-attack_85.pdf",
            "inference-attack_37.pdf",
            "inference-attack_62.pdf",
            "inference-attack_80.pdf",
            "inference-attack_16.pdf"
        ]
    },
    "7": {
        "Top_Words": [
            [
                "client",
                0.055096608970183564
            ],
            [
                "federated",
                0.04735942674902374
            ],
            [
                "fedul",
                0.03847607038725695
            ],
            [
                "learning",
                0.03815523431114697
            ],
            [
                "model",
                0.03507758789565146
            ],
            [
                "unlearning",
                0.030919691348467167
            ],
            [
                "fast",
                0.0253530763432897
            ],
            [
                "datum",
                0.02464859753705389
            ],
            [
                "fl",
                0.024608721093851104
            ],
            [
                "backdoor",
                0.02342836993620964
            ]
        ],
        "Papers": [
            "backdoor-defense_24.pdf",
            "data-poisoning_27.pdf",
            "backdoor-defense_12.pdf",
            "backdoor-attack_36.pdf",
            "drug-discovery_56.pdf"
        ]
    },
    "8": {
        "Top_Words": [
            [
                "agent",
                0.04080293863621922
            ],
            [
                "password",
                0.039394392749088576
            ],
            [
                "llm",
                0.03322758773814757
            ],
            [
                "defense",
                0.03163398605073173
            ],
            [
                "prompt",
                0.026653556685631973
            ],
            [
                "user",
                0.024017746157008673
            ],
            [
                "level",
                0.02061212726714629
            ],
            [
                "setup",
                0.018781898768924162
            ],
            [
                "action",
                0.017680237570240485
            ],
            [
                "block",
                0.016556176058776347
            ]
        ],
        "Papers": [
            "red-teaming_6.pdf",
            "backdoor-attack_7.pdf",
            "backdoor-attack_16.pdf",
            "backdoor-attack_28.pdf",
            "red-teaming_28.pdf"
        ]
    },
    "9": {
        "Top_Words": [
            [
                "leaked",
                0.04112659544912806
            ],
            [
                "ensemble",
                0.031877172782446665
            ],
            [
                "point",
                0.027348604322115246
            ],
            [
                "vime",
                0.0252130768386867
            ],
            [
                "tabnet",
                0.024242190272152585
            ],
            [
                "stg",
                0.024242190272152585
            ],
            [
                "rln",
                0.023753574810548454
            ],
            [
                "dataset",
                0.023638457570159848
            ],
            [
                "tabtr",
                0.022274405367592773
            ],
            [
                "training",
                0.020652827643741992
            ]
        ],
        "Papers": [
            "data-poisoning_23.pdf",
            "adversarial-attack_68.pdf",
            "data-poisoning_84.pdf",
            "adversarial-defense_78.pdf",
            "inference-attack_67.pdf"
        ]
    },
    "10": {
        "Top_Words": [
            [
                "cake",
                0.032147197864112576
            ],
            [
                "instruction",
                0.022448020765107952
            ],
            [
                "answer",
                0.021871999628444952
            ],
            [
                "write",
                0.020307593258358562
            ],
            [
                "response",
                0.016731523511269435
            ],
            [
                "pan",
                0.016703290355735766
            ],
            [
                "ingredient",
                0.014607590951202582
            ],
            [
                "question",
                0.014147380205889973
            ],
            [
                "cool",
                0.013118586243889037
            ],
            [
                "promptinjectionforlongcontext",
                0.012455241591704037
            ]
        ],
        "Papers": [
            "red-teaming_21.pdf",
            "red-teaming_36.pdf",
            "data-poisoning_16.pdf",
            "red-teaming_2.pdf",
            "llm-jailbreak_4.pdf"
        ]
    },
    "11": {
        "Top_Words": [
            [
                "poisoning",
                0.05160893677063446
            ],
            [
                "datum",
                0.03605489094333958
            ],
            [
                "attack",
                0.035126202912784725
            ],
            [
                "poison",
                0.03223261432870976
            ],
            [
                "image",
                0.02464135685103834
            ],
            [
                "trigger",
                0.023343316605906706
            ],
            [
                "ratio",
                0.023196524952754448
            ],
            [
                "training",
                0.021923618755320524
            ],
            [
                "trainingset",
                0.021430190012918012
            ],
            [
                "model",
                0.02103890258154682
            ]
        ],
        "Papers": [
            "data-poisoning_44.pdf",
            "data-poisoning_90.pdf",
            "backdoor-defense_23.pdf",
            "backdoor-attack_74.pdf",
            "data-poisoning_1.pdf"
        ]
    },
    "12": {
        "Top_Words": [
            [
                "spam",
                0.08363382057298996
            ],
            [
                "sms",
                0.058184186997225336
            ],
            [
                "message",
                0.03310435034830027
            ],
            [
                "dataset",
                0.025601159925496136
            ],
            [
                "prompt",
                0.021057442353308174
            ],
            [
                "text",
                0.017607851458353307
            ],
            [
                "character",
                0.017385556832335978
            ],
            [
                "bert",
                0.017236661905763284
            ],
            [
                "model",
                0.01701269901079562
            ],
            [
                "detection",
                0.015348134646640425
            ]
        ],
        "Papers": [
            "backdoor-attack_46.pdf",
            "red-teaming_40.pdf",
            "llm-jailbreak_1.pdf",
            "adversarial-attack_9.pdf",
            "benchmarking_57.pdf"
        ]
    },
    "13": {
        "Top_Words": [
            [
                "backdoor",
                0.02185700873594612
            ],
            [
                "clean",
                0.02169806433614727
            ],
            [
                "trojanrag",
                0.021617534864994258
            ],
            [
                "asr",
                0.021505421879791244
            ],
            [
                "question",
                0.017671802286989977
            ],
            [
                "trigger",
                0.015955110330355942
            ],
            [
                "model",
                0.015896648139930008
            ],
            [
                "task",
                0.015695486345453542
            ],
            [
                "badedit",
                0.01507321700616839
            ],
            [
                "cot",
                0.014955490992118741
            ]
        ],
        "Papers": [
            "backdoor-attack_41.pdf",
            "backdoor-attack_65.pdf",
            "backdoor-attack_52.pdf",
            "data-poisoning_13.pdf"
        ]
    },
    "14": {
        "Top_Words": [
            [
                "diffusion",
                0.04930407961927759
            ],
            [
                "backdoor",
                0.047101499042224715
            ],
            [
                "trigger",
                0.04166708805279652
            ],
            [
                "model",
                0.039888008896733475
            ],
            [
                "diff",
                0.03374245127194159
            ],
            [
                "sampling",
                0.03260474363355906
            ],
            [
                "clean",
                0.03002098877013117
            ],
            [
                "cleanse",
                0.02738787035902753
            ],
            [
                "pruning",
                0.025490539323175323
            ],
            [
                "xb",
                0.024048855510016592
            ]
        ],
        "Papers": [
            "backdoor-defense_13.pdf",
            "backdoor-attack_26.pdf",
            "backdoor-defense_10.pdf",
            "red-teaming_43.pdf"
        ]
    },
    "15": {
        "Top_Words": [
            [
                "al",
                0.04612051322761461
            ],
            [
                "et",
                0.045156018235283375
            ],
            [
                "url",
                0.034784092744296474
            ],
            [
                "language",
                0.029827589928698845
            ],
            [
                "corr",
                0.02805653751246517
            ],
            [
                "doi",
                0.02786331230524147
            ],
            [
                "red",
                0.026193440800400574
            ],
            [
                "model",
                0.02520999514867412
            ],
            [
                "safety",
                0.021195041968450224
            ],
            [
                "lm",
                0.018465194162769163
            ]
        ],
        "Papers": [
            "red-teaming_83.pdf",
            "red-teaming_56.pdf",
            "red-teaming_63.pdf",
            "red-teaming_19.pdf"
        ]
    },
    "16": {
        "Top_Words": [
            [
                "stock",
                0.04006748059278057
            ],
            [
                "market",
                0.03802745198395034
            ],
            [
                "network",
                0.0355085027205555
            ],
            [
                "tuap",
                0.03127600482967667
            ],
            [
                "neural",
                0.02851957027937962
            ],
            [
                "datum",
                0.025930846450835047
            ],
            [
                "perturbation",
                0.02588674569061608
            ],
            [
                "adversarial",
                0.025179827095961466
            ],
            [
                "price",
                0.025029800277872428
            ],
            [
                "xss",
                0.024592109598294845
            ]
        ],
        "Papers": [
            "real-world-adversarial-attack_11.pdf",
            "adversarial-attack_8.pdf",
            "inference-attack_82.pdf",
            "neural-network-security_2.pdf"
        ]
    },
    "17": {
        "Top_Words": [
            [
                "client",
                0.03894089630102185
            ],
            [
                "attack",
                0.037622791622003916
            ],
            [
                "server",
                0.03344810697274482
            ],
            [
                "model",
                0.032754686038728796
            ],
            [
                "learning",
                0.029004246710271617
            ],
            [
                "malicious",
                0.028923183689168165
            ],
            [
                "local",
                0.02831182237905276
            ],
            [
                "datum",
                0.027640476336313582
            ],
            [
                "fssl",
                0.026691591796163597
            ],
            [
                "eminspector",
                0.026343247428780105
            ]
        ],
        "Papers": [
            "backdoor-attack_42.pdf",
            "data-poisoning_97.pdf",
            "data-poisoning_32.pdf"
        ]
    },
    "18": {
        "Top_Words": [
            [
                "flowmur",
                0.0725783207133654
            ],
            [
                "trigger",
                0.061780165669730935
            ],
            [
                "audio",
                0.06054787156858965
            ],
            [
                "sample",
                0.055317335207676004
            ],
            [
                "speech",
                0.04667728968991951
            ],
            [
                "ba",
                0.04492394815179651
            ],
            [
                "attack",
                0.044887139163279605
            ],
            [
                "backdoor",
                0.03635988331777625
            ],
            [
                "asr",
                0.03460350492572559
            ],
            [
                "nba",
                0.034492182140836575
            ]
        ],
        "Papers": [
            "backdoor-attack_70.pdf",
            "data-poisoning_40.pdf",
            "backdoor-attack_91.pdf"
        ]
    },
    "19": {
        "Top_Words": [
            [
                "box",
                0.04072347366271125
            ],
            [
                "black",
                0.029880035980248583
            ],
            [
                "mnist",
                0.028910845763911584
            ],
            [
                "shadowtraining",
                0.027440672301986387
            ],
            [
                "learning",
                0.025890357800671303
            ],
            [
                "classification",
                0.025461041217495883
            ],
            [
                "cs",
                0.022881541362026955
            ],
            [
                "boxsetting",
                0.022030683641785984
            ],
            [
                "ap",
                0.019299182719820947
            ],
            [
                "asurvey",
                0.01884191588199723
            ]
        ],
        "Papers": [
            "inference-attack_72.pdf",
            "inference-attack_54.pdf"
        ]
    },
    "20": {
        "Top_Words": [
            [
                "backdoor",
                0.07051832246360594
            ],
            [
                "problem",
                0.048539664894926185
            ],
            [
                "sdba",
                0.0471748456578721
            ],
            [
                "solution",
                0.044554505061022445
            ],
            [
                "layer",
                0.04175776596234268
            ],
            [
                "les",
                0.036361606731763245
            ],
            [
                "model",
                0.029976864417177212
            ],
            [
                "code",
                0.029672655495484947
            ],
            [
                "team",
                0.02884544186183716
            ],
            [
                "durability",
                0.02764072336253678
            ]
        ],
        "Papers": [
            "red-teaming_68.pdf",
            "backdoor-attack_20.pdf"
        ]
    }
}