{
    "-1": {
        "Top_Words": [
            [
                "medical",
                0.07412382396176793
            ],
            [
                "hallucination",
                0.06830021003051451
            ],
            [
                "al",
                0.048512963916894844
            ],
            [
                "et",
                0.04827258417684284
            ],
            [
                "model",
                0.043876180136855035
            ],
            [
                "ai",
                0.04066812370575499
            ],
            [
                "clinical",
                0.03940598944375873
            ],
            [
                "llm",
                0.0367934294956169
            ],
            [
                "language",
                0.02929754019580659
            ],
            [
                "patient",
                0.02611334586966235
            ]
        ],
        "Papers": [
            "benchmarking_72.pdf",
            "adversarial-defense_68.pdf"
        ]
    },
    "0": {
        "Top_Words": [
            [
                "model",
                0.060803595091931666
            ],
            [
                "attack",
                0.05119046074746868
            ],
            [
                "triple",
                0.04984839053544243
            ],
            [
                "graph",
                0.04134951407456462
            ],
            [
                "adversarial",
                0.03962899370230382
            ],
            [
                "kge",
                0.03734135241181214
            ],
            [
                "knowledge",
                0.03293292426534803
            ],
            [
                "al",
                0.03232821526253423
            ],
            [
                "et",
                0.032044649816232285
            ],
            [
                "target",
                0.03063672850056919
            ]
        ],
        "Papers": [
            "benchmarking_99.pdf",
            "red-teaming_36.pdf",
            "red-teaming_2.pdf",
            "llm-jailbreak_8.pdf",
            "red-teaming_41.pdf",
            "data-poisoning_83.pdf"
        ]
    },
    "1": {
        "Top_Words": [
            [
                "action",
                0.04890771953667197
            ],
            [
                "truth",
                0.040585399645517516
            ],
            [
                "al",
                0.03957735209103017
            ],
            [
                "et",
                0.03948351226841978
            ],
            [
                "reasoning",
                0.03195486589584238
            ],
            [
                "outcome",
                0.02959115111198805
            ],
            [
                "model",
                0.026648781200608544
            ],
            [
                "benchmark",
                0.02503080038607094
            ],
            [
                "task",
                0.02459034516334018
            ],
            [
                "domain",
                0.024534792565222226
            ]
        ],
        "Papers": [
            "benchmarking_81.pdf",
            "red-teaming_79.pdf",
            "benchmarking_5.pdf",
            "red-teaming_19.pdf"
        ]
    }
}